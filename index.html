---
layout: main
---
<body>
  <div class="container">

      <div class="col-xs-12 col-sm-9 col-md-9">

        <div class="row">
        <p>
    	  I am a fourth year PhD student at the <a href="https://www.utoronto.ca">University of Toronto</a> and <a href='https://vectorinstitute.ai/'> Vector Institute</a> under <a href='http://www.marzyehghassemi.com/'>Marzyeh Ghassemi</a> and am a member of the <a href='http://healthyml.org'>Healthy ML</a> lab. Among many exciting things, we broadly investigate novel applications of Reinforcement Learning to assist clinical decision making. Recently, our lab moved to the <a href='https://web.mit.edu/'>Massachusetts Institute of Technology</a> through the <a href='https://imes.mit.edu/'>Institute of Medical Engineering and Sciences</a> where I will be visiting for the remainder of my PhD.
  		</p><p>
        I work in the fields of reinforcement learning, machine
        learning, and causal inference. I have long been interested in
        decision making and the mechanisms by which humans summarize and reason about the world. In my work, I aim to develop models and algorithms that enable actors (whether human or not) to efficiently make decisions in the face of various forms of uncertainty.
      </p><p>
    	  I have been fortunate to collaborate with multiple top research institutions, including <a href="https://www.microsoft.com/en-us/research/">Microsoft Research</a> (long standing relationship with Mehdi Fatemi, 2022 research intern with <a href='https://www.mit.edu/~asolei/'>Ava Amini</a>), <a href='https://research.google/teams/brain/'>Google Brain</a> (2020 research intern with <a href="https://webdocs.cs.ualberta.ca/~machado/">Marlos Machado</a> and <a href="http://www.marcgbellemare.info/">Marc Bellemare</a>), <a href="https://machinelearning.apple.com/research?page=1&tag=Health">Apple Health AI</a> (2021 research intern with Leon Gatys), and <a href="https://unityhealth.to/locations/st-michaels-hospital/">St. Michael's Hospital</a>. I'm always keen on hearing about interesting ideas and love collaborating with others on a variety of problems, applied and foundational, as far as there is alignment with my areas of focus. Don't hesitate to reach out!
      </p><p>
        Previously, I was employed at <a href="https://www.ll.mit.edu//">MIT Lincoln Laboratory</a> and completed degrees at <a href="https://www.harvard.edu">Harvard University</a> (working with <a href="https://finale.seas.harvard.edu">Finale Doshi-Velez</a>) and <a href="https://www.byu.edu">Brigham Young University</a> (working with <a href="https://mae.usu.edu/people/faculty/truscott-tadd">Tadd Truscott</a>).
      </p>
          <!--\\
          <p>
          <ul class="nav nav-pills nav-stacked">
            <li><a href="#publications">Publications</a></li>

            <li><a href="#software">Software</a></li>
            <li><a href="blog">Blog</a></li>

          </ul>
          </p>
      	  -->
        </div>

        <div class="row">
          <h2><a name="news"></a>News</h2>
          <hr>
          <p> 
            <ul class="nav nav-pills nav-stacked">
            <li> 3 November 22 -- Several workshop papers will be presented at NeurIPS this year! I'm looking forward to catching up with friends in New Orleans! </li>
            <li> 18 August 22 -- I've been invited to speak at the NeurIPS Offline RL workshop this November. I will be speaking about my recent Dead-Ends research! </li>
            <li> 20 June 22 -- Starting a summer internship today with Ava Soleimany of Microsoft Research! </li>
            <li> 25 April 22 -- Looking forward to presenting at the MIT x MassGeneralBrigham AI CURES Conference today, soliciting collaborations with clinical researchers to extend our Dead-ends work! </li>
            <li> 18 March 22 -- Two extended abstracts accepted to RLDM, happening this coming June! </li>
            <li> 9 Dec. 21 -- MIT News wrote a nice article about our Medical Dead-ends work that was featured on <a href="https://web.mit.edu/"> MIT's Front Page</a>. The article can be found <a href="https://news.mit.edu/2021/machine-learning-treatments-1209">at this link.</a>
            <li> 28 Sept. 21 -- Our paper investigating medical dead-ends, presenting a novel analytical framework for offline RL settings was accepted for publication at this year's <a href='https://neurips.cc/Conferences/2021'>NeurIPS conference</a>! We're thrilled to have the opportunity to share this paper broadly!</li>
          </p>
        </div>

        <div class="row">
          <h2><a name="publications"></a>Publications</h2>
          <hr>
          <h3>Preprints</h3>
          <p>
          Some of my work is available as
          <a href="https://arxiv.org/a/Killian_T_1.html">preprints on arXiv</a>.
          </p>
          <p>
          	Having lived in Sweden, I put together a brief guide to acquaint co-workers and colleagues with Stockholm. You can find the guide <a href='papers/TWK_Stockholm_Guide.pdf'> here</a>
          </p>
          <h3>2022</h3>
          <p>
            <strong>Continuous Time Evidential Distributions for Processing Irregular Time Series</strong>
            <br>
            We extend recent evidential deep learning approaches to sequential settings in continuous time to deal with irregularly sampled time series such as those one encounters in healthcare. This method provides stable, temporally correlated predictions and corresponding uncertainty estimates based on the evidence gained with each collected observation. The continuous time evidential distribution enables flexible inference of the evolution of the partially observed features at any time of interest, while expanding uncertainty temporally for sparse, irregular observations.
            <br>
            <strong>Taylor W. Killian</strong>, Ava Amini
            <br>
            <a href="https://timeseriesforhealth.github.io/"><em>Learning from Time Series for Health Workshop at NeurIPS</em></a>
          </p>
          <p>
            <strong>Identifying Disparities in Sepsis Treatment using Inverse Reinforcement Learning</strong>
            <br>
            We estimate counterfactual optimal policies (estimated with inverse RL from recorded behavioral data) via subsets of unseen medical populations and identify the difference in care by comparing it to the learned factual policy. We do this to identify deviations across sub-populations of interest and hope this approach helps to identify disparities in care and possible sources of bias underlying them.
            <br>
            Hyewon Jeong, <strong>Taylor W. Killian</strong>, Sanjat Kanjilal, Siddharth Nayak, Marzyeh Ghassemi
            <br>
            <a href="https://sites.google.com/view/wiml2022/"><em>WiML: Women in Machine Learning</em></a> and <a href="https://sites.google.com/view/RL4RealLife"><em>RL4RealLife workshops at NeurIPS</em></a>
          </p>
          <p>
            <strong> Counterfactually Guided Policy Transfer in Clinical Settings</strong>
            <br>
            Domain shift creates significant challenges for sequential decision making in healthcare since the target domain may be both data-scarce and confounded. In this paper, we propose a method for off-policy transfer by modeling the underlying generative process with a causal mechanism. We use informative priors from the source domain to augment counterfactual trajectories in the target in a principled manner. Policy learning in the target domain is further regularized via the source policy through KL-divergence. 
            <br>
            <strong>Taylor W. Killian</strong>, Marzyeh Ghassemi, Shalmali Joshi
            <br>
            <em>Conference on Health, Inference and Learning (CHIL)</em>, 2022
            <div class="btn-group-xs">
              <a href="/papers/KillianGhassemiJoshi_2022CHIL.pdf" class="btn btn-default">Paper</a>
              <a href="/papers/KillianGhassemiJoshi_2022CHIL_poster.pdf" class="btn btn-default">Poster</a>
            </div>
          </p>
          <h3>2021</h3>
          <p>
            <strong> Medical Dead-ends and Learning to Identify High-Risk States and Treatments</strong>
            <br>
            In data-constrained offline settings optimal sequential decision policies may not be attainable. However, negative outcomes in data can be used to identify behaviors to avoid, thereby guarding against overoptimistic decisions in safety-critical domains that may be significantly biased due to reduced data availability. Along these lines we introduce an approach that identifies possible "dead-ends" of a state space as well as high-risk treatments that likely lead to them. We frame the discovery of these dead-ends as an RL problem, training three independent deep neural models for automated state construction, dead-end discovery and confirmation.
            <br>
            Mehdi Fatemi, <strong>Taylor W. Killian</strong>, Jayakumar Subramanian, Marzyeh Ghassemi
            <br>
            <em>Neural Information Processing Systems</em>, 2021
            <div class="btn-group-xs">
              <a href="/papers/FatemiKillianSubramanianGhassemi_2021NeurIPS.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/FatemiKillianSubramanianGhassemi_2021NeurIPS_poster.pdf" class="btn btn-default">Poster</a>
              <a href="https://github.com/microsoft/med-deadend"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <h3>2020</h3>
          <p>
            <strong>An Empirical Study of Representation Learning for Reinforcement Learning in Healthcare</strong>
            <br>
            We investigate several information encoding approaches to develop state representations of patient health from sequential data. We evaluate these representations utility for predicting the next physiological patient observation as well as the development of treatment policies.
            <br>
            <strong>Taylor W. Killian</strong>, Haoran Zhang, Jayakumar Subramanian, Mehdi Fatemi, Maryzeh Ghassemi
            <br>
            <a href="https://ml4health.github.io/2020/"><em>ML4H: Machine Learning for Health Workshop at NeurIPS</em></a>
            <div class='btn-group-xs'>
              <a href="papers/KillianZhangSubramanianFatemiGhassemi_2020ML4H.pdf" class='btn btn-default'>Paper</a>
              <a href="papers/KillianZhangSubramanianFatemiGhassemi_2020ML4H_poster.pdf" class='btn btn-default'>Poster</a>
              <a href="https://github.com/MLforHealth/rl_representations/" class='btn btn-default'>Code</a>
            </div>
          </p>
          <p>
          	<strong>Multiple Sclerosis Severity Classification From Clinical Text</strong>
          	<br>
          	We present the first publicly available transformer model trained on real clinical data other than MIMIC, specifically finetuned for the support of Multiple Sclerosis prediciton and treatment based on clincal consult notes. The model can be found <a href="https://huggingface.co/NLP4H/ms_bert">here</a>
          	<br>
          	Alister D'Costa, Stefan Denkovski, Michal Malyska, Sae Young Moon, Brandon Rufino, Zhen Yang, <strong>Taylor W. Killian</strong>, Marzyeh Ghassemi
          	<br>
          	<a href="https://clinical-nlp.github.io/2020/"><em>The 3rd Clinical Natural Language Processing Workshop</em></a>
          	<div class='btn-group-xs'>
          		<a href='/papers/MSBERT_dCostaDenkovskiMalyskaMoonRufinoYangKillianGhassemiClinicalNLP_2020.pdf' class='btn btn-default'>Paper</a>
          	</div>
          </p>

          <p>
          	<strong>Counterfactual Transfer via Inductive Bias in Clinical Settings</strong>
          	<br>
          	By using counterfactual inference, we establish an approach to transfer learning within offline, off-policy Reinforcement Learning that provides improved policy performance in data-scarce target environments.
          	<br>
          	<strong>Taylor W. Killian</strong>, Marzyeh Ghassemi, Shalmali Joshi
          	<br>
          	<a href="https://biases-invariances-generalization.github.io/"><em>Inductive Biases, Invariances and Generalization in RL (BIG) ICML Workshop</em></a>
          	<div class='btn-group-xs'>
          		<a href="https://biases-invariances-generalization.github.io/pdf/big_40.pdf" class='btn btn-default'>Paper</a>
      		</div>
      	  </p>

          <p>
            <strong>Optimization Methods for Interpretable Differentiable Decision Trees Applied to Reinforcement Learning</strong>
            <br>
            We leverage a differentiable form of a decision tree for Reinforcement Learning which allows for online updates via SGD. From this decision tree, an interpretable policy is extracted. We analyze the optimization behavior of such classes of policies and demonstrate equitable or better performance over batch trained decision trees and similarly sized neural networks.
            <br>
            Andrew Silva, <strong>Taylor W. Killian</strong>, Ivan Rodriguez Jimenez, Sung-Hyun Son, Matthew Gombolay <br>
            <a href='https:aistats.org'>The 23rd International Conference on Artificial Intelligence and Statistics (AISTATS)</a>
            <div class='btn-group-xs'>
            	<a href='/papers/SilvaKillianJimenezSonGombolayAISTATS_2020.pdf' class='btn btn-default'>Paper</a>
            </div>
          </p>
          <h3>2019</h3>
          	<p>
      			<strong> Kernelized Capsule Networks</strong>
      			<br>
      			A hybrid Gaussian Process-Deep Neural Network approach, Kernelized Capsule Networks construct a GP kernel function from the feature representations of a Capsule Network. This combination provides a model robust to adversarial perturbations while also providing a mechanism to detect perturbed inputs.
      			<br>
      			<strong>Taylor W. Killian</strong>, Justin Goodwin, Olivia Brown, Sung-Hyun Son <br>
      			<a href='https://sites.google.com/view/icml2019-generalization/home'><em>1st Workshop on Understanding and Improving Generalization in Deep Learning</em></a>
      			<div class='btn-group-xs'>
      				<a href='/papers/KillianGoodwinBrownSon2019_ICML.pdf' class='btn btn-default'>Paper</a>
      				<a href='/papers/KillianGoodwinBrownSon2019_ICML_poster.pdf' class='btn btn-default'>Poster</a>
      			</div>
      		</p>
          <h3>2018</h3>
	        <p>
	          <strong>Direct Policy Transfer with Hidden Parameter Markov Decision Processes</strong>
	          <br>
	          An extension of the HiP-MDP framework presented in <a href="/papers/KillianDaultonKonidarisFDV2017.pdf">Killian and Daulton, et al (2017)</a> wherein the latent parameters used to describe dynamical variations are included as input to a general policy trained from the optimal policies learned from past instances.
	          <br>
	          Jiayu Yao, <strong>Taylor W. Killian</strong>, George Konidaris, Finale Doshi-Velez<br>
	          <a href="https://sites.google.com/view/llarla2018/home?authuser=0"><em>Lifelong Learning: A Reinforcement Learning Approach Workshop at FAIM 2018</em></a>
	          <div class="btn-group-xs">
	          	<a href="/papers/YaoKillianKonidarisFDV2018_ICML.pdf" class="btn btn-default">Paper</a>
	          	<a href="/papers/YaoKillianKonidarisFDV2018_ICML_poster.pdf" class="btn btn-default">Poster</a>
	          	<a href="/papers/YaoKillianKonidarisFDV2018_ICML_oral.pdf" class="btn btn-default">Slides</a>
	          </div>
          	</p>

          <h3>2017</h3>
          <p>
            <strong>Robust and Efficient Transfer Learning with Hidden Parameter Markov Decision Processes</strong><br>
            A reformulation of the <a href="https://finale.seas.harvard.edu/publications/hidden-parameter-markov-decision-processes-semiparametric-regression-approach-0">HiP-MDP</a> to admit more robust and efficient transfer learning when deployed in complex environments with highly nonlinear dynamics.
            <br>
            <strong>Taylor W. Killian</strong>, Samuel Daulton, George Konidaris, Finale Doshi-Velez<br>
            <em>Neural Information Processing Systems</em>, pp. 6245-6250, 2017
            <div class="btn-group-xs">
              <a href="/papers/KillianDaultonKonidarisFDV2017.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/KillianDaultonKonidarisFDV2017_poster.pdf" class="btn btn-default">Poster</a>
              <a href="https://github.com/dtak/hip-mdp-public"
              class="btn btn-default">Code</a>
              <a href="/talks/hip-mdp_NIPS17oral.pdf"
              class="btn btn-default">Slides</a>
              <a href="https://www.facebook.com/nipsfoundation/videos/1554741347950432/" class="btn btn-default">Video</a> (starts at 17:15)
            </div>
          </p>
          <p>
            <strong>Robust and Efficient Transfer Learning with Hidden Parameter Markov Decision Processes</strong><br>
            An extended abstract of some preliminary transfer learning work. Submitted to the Student Abstract track of AAAI 2017.
            <br>
            <strong>Taylor W. Killian</strong>, George Konidaris, Finale Doshi-Velez<br>
            <em>AAAI</em>, pp.4949-4950. 2017
            <div class="btn-group-xs">
              <a href="/papers/KillianKonidarisFDV2017.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/KillianKonidarisFDV2017_poster.pdf"
              class="btn btn-default">Poster</a>
              <a href="/talks/hip-mdp_AAAI17.pdf"
              class="btn btn-default">Slides</a>
            </div>
          </p>
          <h3>2012</h3>
          <p>
            <strong>Rebound and jet formation of a fluid-filled sphere</strong><br>
            Investigation how fluid filled spheres have little to no rebound when dropped.
            <br>
            <strong>Taylor W. Killian</strong>, Robert A. Klaus, and Tadd T. Truscott<br>
            <em>Physics of Fluids</em>, <strong>24</strong> 122106. 2012.
            <div class="btn-group-xs">
              <a href="/papers/KillianKlausTruscott2012.pdf"
              class="btn btn-default">Paper</a>
              <a href="/talks/2011APSDFD_FINAL.pdf"
              class="btn btn-default">Slides</a>
              <a href="https://www.youtube.com/watch?v=aS2kkk1THmo">Video</a>
            </div>
          </p>

        <hr>
      <<!--
        <div class="row">
          <h2><a href="blog">Blog</a></h2>
        </div>
      -->

      </div>

    <hr>

    <footer>
    &nbsp;
    </footer>

  </div>

  <!-- JavaScript -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/js/bootstrap.min.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'] ],
        processEscapes: true
      }
    });
  </script>
  <script type="text/javascript"
     src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  <script type="text/javascript" src="/js/main.js"></script>
</body>
