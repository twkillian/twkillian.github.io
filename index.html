---
layout: main
---
<body>
  <div class="container">

      <div class="col-xs-12 col-sm-9 col-md-9">

        <div class="row">
          <p>
          I am a Ph.D. student in Computer Science at Columbia, where
          I am advised by
          <a href="http://www.cs.columbia.edu/~blei/">David Blei</a>
          and <a href="http://www.stat.columbia.edu/~gelman/">Andrew
          Gelman</a>.
          I work in the fields of Bayesian statistics, machine
          learning, and deep learning. I am most interested in
          probabilistic models, whether it be in their development,
          inference, or more generally their foundations for
          computational and statistical analysis.
          </p><p>
          I currently work at
          <a href="https://research.google.com/pubs/MachinePerception.html">Google</a>
          and am on leave from Columbia.
          </p><p>
          I lead development of
          <a href="http://edwardlib.org">Edward</a>,
          a library for probabilistic modeling, inference, and
          criticism. I used to be on the
          <a href="http://mc-stan.org">Stan</a> development team.
          Previously, I was a Statistics Ph.D. student at Harvard
          before transferring to Columbia, where I worked with <a
          href="http://www.people.fas.harvard.edu/~airoldi/">Edo
          Airoldi</a>
          and also spent time at the <a
          href="http://hips.seas.harvard.edu/">Harvard Intelligent Probabilistic
          Systems</a> group.
          </p><p>
          Recently, I have been giving the following talk:
          </p>
          <ul>
            <li>
              <div class="btn-group-xs">
                <strong>Edward: A library for probabilistic modeling,
                inference, and criticism</strong>
                <a href="/talks/Tran_Edward.pdf"
                class="btn btn-default">Slides</a>
              </div>
            </li>
          </ul><p>

          <ul class="nav nav-pills nav-stacked">
            <li><a href="#publications">Publications</a></li>
            <li><a href="#software">Software</a></li>
            <li><a href="blog">Blog</a></li>
          </ul>

          </p>
        </div>

        <div class="row">
          <h2><a name="publications"></a>Publications</h2>
          <hr>
          <h3>Preprints</h3>
          <p>
          Some of my work is available as
          <a href="http://arxiv.org/a/tran_d_1.html">preprints on arXiv</a>.
          </p>
          <p>
           <strong>Implicit causal models for genome-wide association
           studies</strong><br>
           Generative models applied to causality in genomics.
           <br>
           <strong>Dustin Tran</strong>, David M. Blei<br>
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1710.10742"
             class="btn btn-default">Paper</a>
           </div>
          </p>
          <p>
            <strong>Expectation propagation as a way of life: A
            framework for Bayesian inference on partitioned
            data</strong><br>
            How to distribute inference with massive data sets and how
            to combine inferences from many data sets.
            <br>
            Andrew Gelman, Aki Vehtari, Pasi Jylänki, Tuomas Sivula,
            <strong>Dustin Tran</strong>, Swupnil Sahai, Paul
            Blomstedt, John P. Cunningham, David Schiminovich,
            Christian Robert<br>
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/1412.4869"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Edward: A library for probabilistic modeling,
            inference, and criticism</strong><br>
            Everything and anything about probabilistic models.
            <br>
            <strong>Dustin Tran</strong>, Alp Kucukelbir, Adji B. Dieng,
            Maja Rudolph, Dawen Liang, David M. Blei<br>
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/1610.09787"
              class="btn btn-default">Paper</a>
              <a href="http://edwardlib.org"
              class="btn btn-default">Website</a>
              <a href="/talks/Tran_Edward.pdf"
              class="btn btn-default">Slides</a>
            </div>
          </p>
          <p>
            <strong>Model criticism for Bayesian causal inference</strong><br>
            How to validate inferences from causal models.
            <br>
            <strong>Dustin Tran</strong>, Francisco J. R. Ruiz, Susan
            Athey, David M. Blei<br>
            <div class="btn-group-xs">
              <a href="http://arxiv.org/abs/1610.09037"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Stochastic gradient descent methods for estimation with
            large data sets</strong><br>
            Fast and statistically efficient algorithms for
            generalized linear models and M-estimation.
            <br>
            <strong>Dustin Tran</strong>, Panos Toulis, Edoardo M.
            Airoldi<br>
            <em>Journal of Statistical Software</em>, To appear
            <div class="btn-group-xs">
              <a href="http://arxiv.org/abs/1509.06459"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/airoldilab/sgd"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <h3>2017</h3>
          <p>
            <strong>Hierarchical implicit models and likelihood-free
            variational inference</strong><br>
            Combining the idea of implicit densities with hierarchical Bayesian
            modeling and deep neural networks.
            <br>
            <strong>Dustin Tran</strong>, Rajesh Ranganath, David M.
            Blei<br>
            <em>Neural Information Processing Systems</em>, 2017
            <div class="btn-group-xs">
              <a href="/papers/TranRanganathBlei2017.pdf"
              class="btn btn-default">Paper</a>
              <a href="http://dustintran.com/blog/deep-and-hierarchical-implicit-models"
              class="btn btn-default">Blog Article</a>
            </div>
          </p>
          <p>
            <strong>Variational inference via $\chi$-upper bound
            minimization</strong><br>
            Overdispersed approximations and upper bounding
            the model evidence.
            <br>
            Adji B. Dieng, <strong>Dustin Tran</strong>, Rajesh
            Ranganath, John Paisley, David M. Blei<br>
            <em>Neural Information Processing Systems</em>, 2017
            <div class="btn-group-xs">
              <a href="/papers/BoussoTranRanganathPaisleyBlei2017.pdf"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/blei-lab/edward"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <p>
            <strong>Comment, "Fast approximate inference for
            arbitrarily large semiparametric regression models via
            message passing"</strong><br>
            The role of message passing in automated inference.
            <br>
            <strong>Dustin Tran</strong>, David M. Blei<br>
            <em>Journal of the American Statistical Association</em>,
            112(517):156–158, 2017
            <div class="btn-group-xs">
              <a href="http://arxiv.org/abs/1609.05615"
              class="btn btn-default">Paper</a>
              <a href="http://dustintran.com/blog/discussion-of-fast-approximate-inference"
              class="btn btn-default">Blog Article</a>
            </div>
          </p>
          <p>
            <strong>Automatic differentiation variational inference</strong><br>
            An automated tool for black box variational inference,
            available in Stan.
            <br>
            Alp Kucukelbir, <strong>Dustin Tran</strong>, Rajesh Ranganath,
            Andrew Gelman, David M. Blei<br>
            <em>Journal of Machine Learning Research</em>, 18(14):1–45, 2017
            <div class="btn-group-xs">
              <a href="/papers/KucukelbirTranRanganathGelmanBlei2017.pdf"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/stan-dev/stan"
              class="btn btn-default">Code</a>
              <a href="/talks/Tran_Automating.pdf"
              class="btn btn-default">Slides</a>
            </div>
          </p>
          <p>
            <strong>Deep probabilistic programming</strong><br>
            How to build a language with rich compositionality for
            modeling and inference.
            <br>
            <strong>Dustin Tran</strong>, Matthew D. Hoffman, Rif A.
            Saurous, Eugene Brevdo, Kevin Murphy, David M. Blei<br>
            <em>International Conference on Learning Representations</em>, 2017
            <div class="btn-group-xs">
              <a href="/papers/TranHoffmanSaurousBrevdoMurphyBlei2017.pdf"
              class="btn btn-default">Paper</a>
              <a href="http://edwardlib.org/iclr2017"
              class="btn btn-default">Website</a>
              <a href="/papers/TranHoffmanMurphyBrevdoSaurousBlei2017_poster.pdf"
              class="btn btn-default">Poster</a>
              <a href="/talks/Tran_Edward.pdf"
              class="btn btn-default">Slides</a>
            </div>
          </p>
          <h3>2016</h3>
          <p>
            <strong>Operator variational inference</strong><br>
            How to formalize computational and statistical tradeoffs in variational inference.
            <br>
            Rajesh Ranganath, Jaan Altosaar, <strong>Dustin
            Tran</strong>, and David M. Blei<br>
            <em>Neural Information Processing Systems</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/RanganathAltosaarTranBlei2016.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/RanganathAltosaarTranBlei2016_poster.pdf"
              class="btn btn-default">Poster</a>
            </div>
          </p>
          <p>
            <strong>Hierarchical variational models</strong><br>
            A Bayesian formalism for constructing expressive
            variational families.
            <br>
            Rajesh Ranganath, <strong>Dustin Tran</strong>, David M.
            Blei<br>
            <em>International Conference on Machine Learning</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/RanganathTranBlei2016.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/RanganathTranBlei2016_poster.pdf"
              class="btn btn-default">Poster</a>
            </div>
          </p>
          <p>
            <strong>Spectral M-estimation with application to hidden
            Markov models</strong><br>
            Applying M-estimation for sample efficiency and robustness
            in moment-based estimators.
            <br>
            <strong>Dustin Tran</strong>, Minjae Kim, Finale Doshi-Velez<br>
            <em>Artificial Intelligence and Statistics</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/TranKimDoshi-Velez2016.pdf"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Towards stability and optimality in stochastic gradient
            descent</strong><br>
            A stochastic gradient method combining numerical stability
            and statistical efficiency.
            <br>
            Panos Toulis, <strong>Dustin Tran</strong>, Edoardo M.
            Airoldi<br>
            <em>Artificial Intelligence and Statistics</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/ToulisTranAiroldi2016.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/ToulisTranAiroldi2016_poster.pdf"
              class="btn btn-default">Poster</a>
              <a href="https://github.com/airoldilab/sgd"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <p>
            <strong>The variational Gaussian process</strong><br>
            A powerful variational model that can universally
            approximate any posterior.
            <br>
            <strong>Dustin Tran</strong>, Rajesh Ranganath, David M.
            Blei<br>
            <em>International Conference on Learning Representations</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/TranRanganathBlei2016.pdf"
              class="btn btn-default">Paper</a>
              <a href="/talks/Tran_Variational.pdf"
              class="btn btn-default">Slides</a>
            </div>
          </p>
          <h3>2015</h3>
          <p>
            <strong>Copula variational inference</strong><br>
            Posterior approximations using copulas, which find
            meaningful dependence between latent variables.
            <br>
            <strong>Dustin Tran</strong>, David M. Blei, Edoardo M.
            Airoldi<br>
            <em>Neural Information Processing Systems</em>, 2015
            <div class="btn-group-xs">
              <a href="/papers/TranBleiAiroldi2015.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/TranBleiAiroldi2015_poster.pdf"
              class="btn btn-default">Poster</a>
            </div>
          </p>
        </div>

        <div class="row">
          <h2><a name="software"></a>Software</h2>
          <hr>
          <div class="col-md-4">
            <a href="http://edwardlib.org">
              <img src="img/edward.png" style="height:200px;width:200px;"/>
            </a>
            <p>
              <h3>Edward</h3><br>
              <a href="http://edwardlib.org">Edward</a> is a Python
              library for probabilistic modeling, inference, and
              criticism. It is a testbed for fast experimentation and
              research with probabilistic models, ranging from
              classical hierarchical models on small data sets to
              complex deep probabilistic models on large data sets.
            </p>
          </div>
          <div class="col-md-4">
            <a href="https://github.com/tensorflow">
              <img src="img/tensorflow.png" style="height:200px;width:200px;"/>
            </a>
            <p>
              <h3>TensorFlow Probability</h3><br>
              To be announced.
            </p>
          </div>
          <div class="col-md-4">
            <a href="https://github.com/edwardlib/observations">
              <div style="height:200px;width:200px;"></div>
            </a>
            <p>
              <h3>Observations</h3><br>
              <a href="https://github.com/edwardlib/observations">Observations</a>
              provides a one line Python API for loading
              standard data sets in machine learning. It automates the
              process from downloading, extracting, loading, and
              preprocessing data. Observations helps keep the workflow
              reproducible and follow sensible standards.
            </p>
          </div>
        </div>

        <hr>

        <div class="row">
          <h2><a href="blog">Blog</a></h2>
        </div>

      </div>

    <hr>

    <footer>
    &nbsp;
    </footer>

  </div>

  <!-- JavaScript -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/js/bootstrap.min.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'] ],
        processEscapes: true
      }
    });
  </script>
  <script type="text/javascript"
     src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  <script type="text/javascript" src="/js/main.js"></script>
</body>
